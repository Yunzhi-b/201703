{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is for CKN of just one layer by using gradientmap as the initial map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Doesn't work well**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 3072) (5000, 2) (2000, 3072)\n"
     ]
    }
   ],
   "source": [
    "path1 = \"Xtr.csv\"\n",
    "path2 = \"Ytr.csv\"\n",
    "path3 = \"Xte.csv\"\n",
    "#  training images\n",
    "Xtr = pd.read_csv(path1,header=None).dropna(axis='columns', how='all')\n",
    "Ytr = pd.read_csv(path2)\n",
    "#  test images\n",
    "Xte = pd.read_csv(path3,header=None).dropna(axis='columns', how='all')\n",
    "\n",
    "print (Xtr.shape,Ytr.shape,Xte.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "two initial maps: \n",
    "- batch map, shape = (32,32,3)\n",
    "- gradient map, (colored) shape = (2,32,32,3), \"2\" because each element is (gradX,gradY)=RxR, gradients on two directions X,Y \n",
    "                (gray) shape = (2,32,32) \n",
    "\"\"\"\n",
    "# batch map\n",
    "# data.shape\n",
    "\n",
    "def batchmap(image):\n",
    "    r,c = image.shape\n",
    "    batch = []\n",
    "    for idx in range(r):\n",
    "        tmp = image.ix[idx]\n",
    "        R_channel,G_channel,B_channel = tmp[:1024],tmp[1024:2048],tmp[2048:]\n",
    "        R,G,B = np.reshape(R_channel,(32,32,1)),np.reshape(G_channel,(32,32,1)),np.reshape(B_channel,(32,32,1))\n",
    "        batch.append(np.concatenate((R,G,B),axis=2))\n",
    "    return batch\n",
    "\n",
    "def gradientmap_grey(image):\n",
    "    r,c = image.shape\n",
    "    gradient =[]\n",
    "    for idx in range(r):\n",
    "        tmp = image.ix[idx]\n",
    "        R_channel,G_channel,B_channel = tmp[:1024],tmp[1024:2048],tmp[2048:]\n",
    "        grey = np.mean( np.array([ R_channel, G_channel,B_channel ]), axis=0 )\n",
    "        grey = np.reshape(grey,(32,32))\n",
    "        grad_x, grad_y = np.gradient(grey)\n",
    "        grad_x = grad_x.reshape((32,32,1))\n",
    "        grad_y = grad_y.reshape((32,32,1))\n",
    "        gradient.append(np.concatenate((grad_x,grad_y),axis=2))\n",
    "    aaaa = np.reshape(gradient,(-1,2))\n",
    "    ss = []\n",
    "    for i in range(len(aaaa)):\n",
    "        ss.append(np.arctan(aaaa[i][0]/aaaa[i][1]))\n",
    "    s = np.reshape(ss,(-1,32,32))\n",
    "    return s\n",
    "\n",
    "def gradientmap_color(image):\n",
    "    r,c = image.shape\n",
    "    gradient =[]\n",
    "    for idx in range(r):\n",
    "        tmp = image.ix[idx]\n",
    "        R_channel,G_channel,B_channel = tmp[:1024],tmp[1024:2048],tmp[2048:]\n",
    "        R,G,B = np.reshape(R_channel,(32,32)),np.reshape(G_channel,(32,32)),np.reshape(B_channel,(32,32))\n",
    "        grad_Rx, grad_Ry = np.gradient(R)\n",
    "        grad_Gx, grad_Gy = np.gradient(G)\n",
    "        grad_Bx, grad_By = np.gradient(B)\n",
    "        gradient.append(np.concatenate((grad_Rx.reshape(32,32,1),grad_Ry.reshape(32,32,1),grad_Gx.reshape(32,32,1)\n",
    "                                        ,grad_Gy.reshape(32,32,1),grad_Bx.reshape(32,32,1),grad_By.reshape(32,32,1)),axis=2))\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 32, 32)\n",
      "1\n",
      "(9, 1)\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "from numpy.random import normal\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "\"\"\"\n",
    "convolution and non-linearity\n",
    "\n",
    "listmaps: shape=(n,n)\n",
    "\"\"\"\n",
    "\n",
    "patch_shape = 3\n",
    "p = 1\n",
    "sigma = 5\n",
    "gamma=10 \n",
    "\n",
    "X_tr = np.nan_to_num(gradientmap_grey(Xtr))\n",
    "\n",
    "#n_channel = np.shape(gradmap1)[-1]\n",
    "n_channel = 1\n",
    "print(np.shape(X_tr))\n",
    "print(n_channel)\n",
    "W = np.random.normal(0, sigma, (n_channel*patch_shape**2, p))\n",
    "eta = 1./p *np.ones(p)\n",
    "print(np.shape(W))\n",
    "\n",
    "\n",
    "def activation_map (listmaps):\n",
    "#    t0 = time.clock()\n",
    "    n = listmaps.shape[0]\n",
    "    fi = np.array([listmaps[i:i+patch_shape,j:j+patch_shape] for i in range(n-patch_shape+1) for j in range(n-patch_shape+1)]) # fi[i]=(3x3x3),len(fi)=900 \n",
    "    fi_norm = np.array([norm(t) for t in fi]) #len(fi_norm)=900\n",
    "    tmp1 = len(fi)\n",
    "    fi_new = np.array([np.ravel(fi[i]/fi_norm[i]) for i in range(tmp1)])  #(27*900)\n",
    "    v = [fi_norm[j]*np.sqrt(eta[i])*np.exp(-(1./sigma**2)*(norm(fi_new[j]-W[:,i])**2)) for i in range(p) for j in range(tmp1)]\n",
    "    v = np.reshape(v,(n-patch_shape+1,n-patch_shape+1,p))\n",
    "#    print(\"one:\" + str(time.clock()-t0))\n",
    "    return v\n",
    "\n",
    "def feature_pooling(listmaps):\n",
    "#    t0 = time.clock()\n",
    "    n = listmaps.shape[0]\n",
    "    l = np.reshape(listmaps,(n*n,p))\n",
    "    coor = np.array([[i,j] for i in range(n) for j in range(n)])\n",
    "    output = []\n",
    "    for i in range(0,n,gamma):\n",
    "        for j in range(0,n,gamma):\n",
    "            center = np.array([i+gamma/2.,j+gamma/2.])\n",
    "            tmp = 0\n",
    "            for k in np.arange(n*n):\n",
    "                tmp = tmp + np.exp(-1/(gamma**2)*(norm(coor[k]-center)**2))*l[k]   \n",
    "            output.append(np.sqrt(2./np.pi)*tmp)\n",
    "    d = len(np.arange(0,n,gamma))\n",
    "    output = np.reshape(output,(d,d,p))\n",
    "#    print(\"two:\" + str(time.clock()-t0))\n",
    "#    print(output.shape)\n",
    "    return output\n",
    "\n",
    "def feature_pooling_all(input_map):\n",
    "    t0 = time.clock()\n",
    "    out_put = []\n",
    "    output_inter = []\n",
    "    for tmp in input_map:\n",
    "#        t0 = time.clock()\n",
    "        actmap = activation_map(tmp)\n",
    "        output_inter.append(actmap)\n",
    "        out_put.append(feature_pooling(actmap))\n",
    "#        print(\"time:\"+str(time.clock()-t0))\n",
    "    print(\"time:\"+str(time.clock()-t0))\n",
    "    return out_put, output_inter\n",
    "\n",
    "def kernel_producing(x1,x2):\n",
    "    #x1 est sample test, x2 est sample train\n",
    "    x1 = np.reshape(x1,(len(x1),-1))\n",
    "    x2 = np.reshape(x2,(len(x2),-1))\n",
    "    return np.dot(x1,x2.T)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:12.426470000000336\n"
     ]
    }
   ],
   "source": [
    "X_tr_f, X_tr_i = feature_pooling_all(X_tr[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K_train = kernel_producing(X_tr_f,X_tr_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_te = np.nan_to_num(gradientmap_grey(Xte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:12.256049000000075\n"
     ]
    }
   ],
   "source": [
    "X_te_f, X_te_i = feature_pooling_all(X_te[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K_test = kernel_producing(X_te_f,X_tr_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = Ytr['Prediction'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.325\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tr_f, Ytr['Prediction'].values, test_size=0.2)\n",
    "clf = SVC(C=1,kernel='precomputed',gamma='auto')\n",
    "clf.fit(np.nan_to_num(kernel_producing(X_train,X_train)),y_train)\n",
    "print(clf.score(np.nan_to_num(kernel_producing(X_train,X_train)),y_train))\n",
    "print(clf.score(np.nan_to_num(kernel_producing(X_test,X_train)),y_test))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
