{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 3072) (5000, 2) (2000, 3072)\n"
     ]
    }
   ],
   "source": [
    "path1 = \"Xtr.csv\"\n",
    "path2 = \"Ytr.csv\"\n",
    "path3 = \"Xte.csv\"\n",
    "#  training images\n",
    "Xtr = pd.read_csv(path1,header=None).dropna(axis='columns', how='all')\n",
    "Ytr = pd.read_csv(path2)\n",
    "#  test images\n",
    "Xte = pd.read_csv(path3,header=None).dropna(axis='columns', how='all')\n",
    "\n",
    "print (Xtr.shape,Ytr.shape,Xte.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3062</th>\n",
       "      <th>3063</th>\n",
       "      <th>3064</th>\n",
       "      <th>3065</th>\n",
       "      <th>3066</th>\n",
       "      <th>3067</th>\n",
       "      <th>3068</th>\n",
       "      <th>3069</th>\n",
       "      <th>3070</th>\n",
       "      <th>3071</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007018</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.002215</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>-0.005636</td>\n",
       "      <td>-0.001525</td>\n",
       "      <td>-0.001090</td>\n",
       "      <td>-0.001907</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>-0.004225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004146</td>\n",
       "      <td>-0.002166</td>\n",
       "      <td>-0.005094</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>-0.006143</td>\n",
       "      <td>-0.013265</td>\n",
       "      <td>-0.013873</td>\n",
       "      <td>0.005223</td>\n",
       "      <td>-0.000860</td>\n",
       "      <td>-0.012881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000819</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>0.004685</td>\n",
       "      <td>0.011166</td>\n",
       "      <td>0.017482</td>\n",
       "      <td>0.045989</td>\n",
       "      <td>0.031377</td>\n",
       "      <td>0.032150</td>\n",
       "      <td>0.062066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000530</td>\n",
       "      <td>0.007203</td>\n",
       "      <td>0.008634</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.014114</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>-0.019384</td>\n",
       "      <td>-0.046763</td>\n",
       "      <td>-0.048919</td>\n",
       "      <td>-0.057449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.016779</td>\n",
       "      <td>0.006662</td>\n",
       "      <td>-0.007226</td>\n",
       "      <td>-0.003798</td>\n",
       "      <td>-0.004273</td>\n",
       "      <td>-0.009955</td>\n",
       "      <td>-0.030925</td>\n",
       "      <td>-0.007064</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029953</td>\n",
       "      <td>-0.023748</td>\n",
       "      <td>0.047707</td>\n",
       "      <td>0.072310</td>\n",
       "      <td>0.056837</td>\n",
       "      <td>0.045410</td>\n",
       "      <td>0.015561</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>-0.013745</td>\n",
       "      <td>0.000968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014936</td>\n",
       "      <td>0.004218</td>\n",
       "      <td>0.009732</td>\n",
       "      <td>0.007309</td>\n",
       "      <td>0.004914</td>\n",
       "      <td>0.008172</td>\n",
       "      <td>0.014205</td>\n",
       "      <td>-0.023263</td>\n",
       "      <td>-0.023014</td>\n",
       "      <td>0.011482</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004505</td>\n",
       "      <td>-0.029634</td>\n",
       "      <td>-0.024069</td>\n",
       "      <td>-0.000788</td>\n",
       "      <td>-0.005010</td>\n",
       "      <td>-0.004260</td>\n",
       "      <td>0.014308</td>\n",
       "      <td>-0.010997</td>\n",
       "      <td>-0.025966</td>\n",
       "      <td>-0.025786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.073091</td>\n",
       "      <td>-0.046800</td>\n",
       "      <td>-0.056235</td>\n",
       "      <td>-0.063619</td>\n",
       "      <td>-0.088387</td>\n",
       "      <td>-0.044682</td>\n",
       "      <td>-0.014172</td>\n",
       "      <td>-0.077535</td>\n",
       "      <td>-0.100056</td>\n",
       "      <td>-0.066161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011063</td>\n",
       "      <td>-0.018166</td>\n",
       "      <td>0.012983</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>0.014233</td>\n",
       "      <td>0.047403</td>\n",
       "      <td>0.052239</td>\n",
       "      <td>-0.029272</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>-0.001475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3072 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.007018  0.000323  0.002215  0.000781 -0.005636 -0.001525 -0.001090   \n",
       "1  0.000819  0.001688  0.002698  0.004685  0.011166  0.017482  0.045989   \n",
       "2 -0.016779  0.006662 -0.007226 -0.003798 -0.004273 -0.009955 -0.030925   \n",
       "3  0.014936  0.004218  0.009732  0.007309  0.004914  0.008172  0.014205   \n",
       "4 -0.073091 -0.046800 -0.056235 -0.063619 -0.088387 -0.044682 -0.014172   \n",
       "\n",
       "       7         8         9       ...         3062      3063      3064  \\\n",
       "0 -0.001907  0.004179 -0.004225    ...     0.004146 -0.002166 -0.005094   \n",
       "1  0.031377  0.032150  0.062066    ...    -0.000530  0.007203  0.008634   \n",
       "2 -0.007064  0.008136  0.000618    ...    -0.029953 -0.023748  0.047707   \n",
       "3 -0.023263 -0.023014  0.011482    ...    -0.004505 -0.029634 -0.024069   \n",
       "4 -0.077535 -0.100056 -0.066161    ...     0.011063 -0.018166  0.012983   \n",
       "\n",
       "       3065      3066      3067      3068      3069      3070      3071  \n",
       "0  0.001906 -0.006143 -0.013265 -0.013873  0.005223 -0.000860 -0.012881  \n",
       "1  0.006800  0.014114  0.000243 -0.019384 -0.046763 -0.048919 -0.057449  \n",
       "2  0.072310  0.056837  0.045410  0.015561  0.003272 -0.013745  0.000968  \n",
       "3 -0.000788 -0.005010 -0.004260  0.014308 -0.010997 -0.025966 -0.025786  \n",
       "4  0.022676  0.014233  0.047403  0.052239 -0.029272  0.001368 -0.001475  \n",
       "\n",
       "[5 rows x 3072 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Prediction\n",
       "0   1           8\n",
       "1   2           9\n",
       "2   3           3\n",
       "3   4           1\n",
       "4   5           4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Ytr.Prediction.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = Ytr.Prediction.values\n",
    "X = Xtr.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 9 3 ..., 1 7 5]\n",
      "[[  7.01830600e-03   3.23271000e-04   2.21460900e-03 ...,   5.22321100e-03\n",
      "   -8.60397000e-04  -1.28809100e-02]\n",
      " [  8.18818000e-04   1.68826600e-03   2.69750200e-03 ...,  -4.67626500e-02\n",
      "   -4.89189000e-02  -5.74489200e-02]\n",
      " [ -1.67785700e-02   6.66184700e-03  -7.22571200e-03 ...,   3.27242800e-03\n",
      "   -1.37449300e-02   9.68480300e-04]\n",
      " ..., \n",
      " [  4.96795100e-02   5.04228400e-02   1.20012000e-02 ...,  -1.33938600e-02\n",
      "   -1.55300600e-02  -1.54807700e-03]\n",
      " [  4.41655500e-05   5.98973100e-04   1.81899700e-04 ...,   1.61626500e-02\n",
      "    2.53539900e-02   3.46440700e-02]\n",
      " [  2.33407600e-02  -4.58995900e-03  -1.10315000e-02 ...,  -2.51070900e-02\n",
      "   -2.56246400e-02   1.40205900e-02]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(X)\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3062</th>\n",
       "      <th>3063</th>\n",
       "      <th>3064</th>\n",
       "      <th>3065</th>\n",
       "      <th>3066</th>\n",
       "      <th>3067</th>\n",
       "      <th>3068</th>\n",
       "      <th>3069</th>\n",
       "      <th>3070</th>\n",
       "      <th>3071</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021317</td>\n",
       "      <td>-0.029188</td>\n",
       "      <td>-0.021746</td>\n",
       "      <td>-0.029482</td>\n",
       "      <td>0.011179</td>\n",
       "      <td>0.032251</td>\n",
       "      <td>0.013757</td>\n",
       "      <td>0.015677</td>\n",
       "      <td>-0.049118</td>\n",
       "      <td>-0.051430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016902</td>\n",
       "      <td>0.013725</td>\n",
       "      <td>0.123213</td>\n",
       "      <td>-0.006638</td>\n",
       "      <td>-0.043762</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.003506</td>\n",
       "      <td>-0.007296</td>\n",
       "      <td>-0.020889</td>\n",
       "      <td>-0.024223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.038809</td>\n",
       "      <td>0.017464</td>\n",
       "      <td>0.033951</td>\n",
       "      <td>0.062252</td>\n",
       "      <td>0.051475</td>\n",
       "      <td>0.071586</td>\n",
       "      <td>0.076982</td>\n",
       "      <td>0.078035</td>\n",
       "      <td>0.058132</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>-0.010371</td>\n",
       "      <td>-0.016821</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>-0.007583</td>\n",
       "      <td>-0.024359</td>\n",
       "      <td>-0.002662</td>\n",
       "      <td>-0.003553</td>\n",
       "      <td>-0.000605</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.013505</td>\n",
       "      <td>-0.040433</td>\n",
       "      <td>-0.023872</td>\n",
       "      <td>-0.017034</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>-0.005875</td>\n",
       "      <td>-0.028056</td>\n",
       "      <td>-0.005516</td>\n",
       "      <td>-0.025364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.008904</td>\n",
       "      <td>0.010832</td>\n",
       "      <td>-0.000609</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>-0.006280</td>\n",
       "      <td>0.018178</td>\n",
       "      <td>0.009699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.079833</td>\n",
       "      <td>0.087111</td>\n",
       "      <td>0.095980</td>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.090196</td>\n",
       "      <td>0.092923</td>\n",
       "      <td>0.085450</td>\n",
       "      <td>0.093836</td>\n",
       "      <td>0.089580</td>\n",
       "      <td>0.089868</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004682</td>\n",
       "      <td>0.003782</td>\n",
       "      <td>0.015810</td>\n",
       "      <td>0.006891</td>\n",
       "      <td>-0.001391</td>\n",
       "      <td>0.005947</td>\n",
       "      <td>0.015124</td>\n",
       "      <td>0.012474</td>\n",
       "      <td>-0.013197</td>\n",
       "      <td>-0.037887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003421</td>\n",
       "      <td>-0.012074</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>0.002495</td>\n",
       "      <td>0.017810</td>\n",
       "      <td>0.009306</td>\n",
       "      <td>-0.011229</td>\n",
       "      <td>-0.040445</td>\n",
       "      <td>-0.028034</td>\n",
       "      <td>0.059742</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015567</td>\n",
       "      <td>0.004841</td>\n",
       "      <td>0.013999</td>\n",
       "      <td>0.020970</td>\n",
       "      <td>0.043955</td>\n",
       "      <td>0.026964</td>\n",
       "      <td>0.030705</td>\n",
       "      <td>-0.002225</td>\n",
       "      <td>0.009616</td>\n",
       "      <td>0.006040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3072 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.021317 -0.029188 -0.021746 -0.029482  0.011179  0.032251  0.013757   \n",
       "1  0.038809  0.017464  0.033951  0.062252  0.051475  0.071586  0.076982   \n",
       "2 -0.013505 -0.040433 -0.023872 -0.017034  0.005898  0.015000 -0.005875   \n",
       "3  0.079833  0.087111  0.095980  0.085299  0.090196  0.092923  0.085450   \n",
       "4  0.003421 -0.012074  0.003435  0.002495  0.017810  0.009306 -0.011229   \n",
       "\n",
       "       7         8         9       ...         3062      3063      3064  \\\n",
       "0  0.015677 -0.049118 -0.051430    ...     0.016902  0.013725  0.123213   \n",
       "1  0.078035  0.058132  0.008797    ...     0.001799 -0.010371 -0.016821   \n",
       "2 -0.028056 -0.005516 -0.025364    ...     0.000643  0.000917  0.008904   \n",
       "3  0.093836  0.089580  0.089868    ...    -0.004682  0.003782  0.015810   \n",
       "4 -0.040445 -0.028034  0.059742    ...    -0.015567  0.004841  0.013999   \n",
       "\n",
       "       3065      3066      3067      3068      3069      3070      3071  \n",
       "0 -0.006638 -0.043762 -0.011082 -0.003506 -0.007296 -0.020889 -0.024223  \n",
       "1  0.008783 -0.007583 -0.024359 -0.002662 -0.003553 -0.000605  0.000030  \n",
       "2  0.010832 -0.000609  0.001183  0.000750 -0.006280  0.018178  0.009699  \n",
       "3  0.006891 -0.001391  0.005947  0.015124  0.012474 -0.013197 -0.037887  \n",
       "4  0.020970  0.043955  0.026964  0.030705 -0.002225  0.009616  0.006040  \n",
       "\n",
       "[5 rows x 3072 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xte.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (pd.isnull(Xtr).values.any(), pd.isnull(Ytr).values.any(), pd.isnull(Xte).values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Xtr: (5000, 3072)\n",
    "One row represents a color image of size 32 x 32 pixels. \n",
    "The first 1024 values represent pixel intensities on the red channel, \n",
    "then the next 1024 represent the green channel, \n",
    "and the last 1024 entries, the blue channel. \n",
    "\n",
    "\"\"\"\n",
    "tmp = Xtr.ix[0]\n",
    "\n",
    "R_channel = tmp[:1024]\n",
    "G_channel = tmp[1024:2048]\n",
    "B_channel = tmp[2048:]\n",
    "#print len(R_channel),len(G_channel),len(B_channel)\n",
    "R = np.reshape(R_channel,(32,32,1))\n",
    "G = np.reshape(G_channel,(32,32,1))\n",
    "B = np.reshape(B_channel,(32,32,1))\n",
    "\n",
    "%matplotlib inline \n",
    "data = np.concatenate((R,G,B),axis=2)\n",
    "plt.imshow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load utilities/KNN-kernel.py\n",
    "\"\"\"\n",
    "Classifier implementing the k-nearest neighbors vote. \n",
    "\n",
    "Parameters:\n",
    "    1) n_neighbors : int, optional (default = 30)\n",
    "    2) weights : str (default = 'uniform), weight function used in prediction. \n",
    "        - 'uniform' : uniform weights. All points in each neighborhood are weighted equally.\n",
    "        - 'distance' : weight points by the inverse of their distance.\n",
    "\n",
    "Methods: \n",
    "    1) knn = KNNClassifier(n_neighbors,weights,kernel) : initialize a KNN classifier.\n",
    "    2) fit(X, y) : Fit the model using X as training data and y as target values.\n",
    "    3) predict(X) : Predict the class labels for the provided data.\n",
    "    4) score(X, y) : Returns the mean accuracy on the given test data and labels.\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import mode\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "from kernel_metrics import dist_kernel\n",
    "\n",
    "def weighted_mode(a,w):\n",
    "    \"\"\"Returns an array of the weighted modal (most common) value in a\n",
    "    If there is more than one such value, only the first is returned.\n",
    "    The bin-count for the modal bins is also returned.\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> x = [4, 1, 4, 2, 4, 2]\n",
    "    >>> weights = [1, 3, 0.5, 1.5, 1, 2] # deweight the 4's\n",
    "    >>> weighted_mode(x, weights)\n",
    "    (array([ 2.]), array([ 3.5]))\n",
    "    The value 2 has the highest score: it appears twice with weights of\n",
    "    1.5 and 2: the sum of these is 3.\n",
    "\n",
    "    \"\"\"\n",
    "    a = np.ravel(a)\n",
    "    w = np.ravel(w)\n",
    "    \n",
    "    all_labels = np.unique(np.ravel(a))       # get ALL unique values\n",
    "    oldlabel = 0\n",
    "    oldcounts = 0\n",
    "    for label in all_labels:\n",
    "        template = np.zeros(a.shape)\n",
    "        idx = (a == label)\n",
    "        template[idx] = w[idx]\n",
    "        counts = np.sum(template)\n",
    "        label_freq = np.where(counts > oldcounts, label, oldlabel) # if counts>oldcounts, label_freq = label; else mostfrequent = oldlabel\n",
    "        oldcounts = np.maximum(counts, oldcounts)\n",
    "        oldlabel = label_freq\n",
    "    return label_freq, oldcounts\n",
    "\n",
    "\n",
    "\n",
    "class KNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self,  n_neighbors=30,weights='uniform',kernel=None, param=None):\n",
    "        self.n_neighbors=n_neighbors\n",
    "        self.weights = weights\n",
    "        self.kernel=kernel\n",
    "        self.param = param\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Compute all pairwise distances between X and self.X_      \n",
    "        # mean_x = np.mean(X,axis=0)\n",
    "        # std_x = np.std(X,axis=0)\n",
    "        # X = (X - mean_x) / std_x\n",
    "        # mean_self = np.mean(self.X_,axis=0)\n",
    "        # std_self = np.std(self.X_,axis=0)\n",
    "        # self.X_ = (self.X_ - mean_self) / std_self\n",
    "        \n",
    "        if self.kernel==None:\n",
    "            all_distance=distance.cdist(self.X_,X,'euclidean')\n",
    "        else:\n",
    "            all_distance=dist_kernel(self.X_,X,self.kernel,self.param) \n",
    "        \n",
    "        # Find the predicted labels y for each entry in X\n",
    "        y=np.array([])\n",
    "        for i in range(n_samples):\n",
    "            arr = all_distance[:,i]\n",
    "            idx = arr.argsort()[:self.n_neighbors] # index of n_neighbors nearest points \n",
    "            \n",
    "            if (self.weights =='uniform'):\n",
    "                y=np.append(y,mode(self.y_[idx])[0]) \n",
    "                \n",
    "            elif (self.weights=='distance'): \n",
    "                # weights proportional to the inverse of the distance from the query point.        \n",
    "                w = [1./x  for x in arr]\n",
    "                w_ = [w[i] for i in idx] \n",
    "                y = np.append(y,weighted_mode(self.y_[idx],w_)[0])\n",
    "                \n",
    "            else:\n",
    "                print (\"Error: Invalide parameter.\")\n",
    "          \n",
    "        return y\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return np.mean(self.predict(X) == y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtr.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xtr.values, Ytr['Prediction'].values, test_size=0.2)\n",
    "\n",
    "dict_param = {'gamma':2.}\n",
    "clf =KNNClassifier(n_neighbors=10,weights='uniform',kernel='gaussian',param = dict_param)\n",
    "clf.fit(X_train, y_train)\n",
    "score = cross_val_score(clf, X_test, y_test, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Logistic regression & multiclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def obj_logistic(alpha,K,y,C):\n",
    "    return np.mean(np.log(1+np.exp(-y*(K.dot(alpha)))))+C/2.*alpha.T.dot(K).dot(alpha)\n",
    "\n",
    "class LogisticClassifier():\n",
    "    def __init__(self, C=None, kernel=None, param=None):\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "        self.param = param\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        K = self.kernel(self.X_,self.X_)\n",
    "        n = X.shape[0]\n",
    "        alpha0 = np.random.normal(0,0.1,n)[:,np.newaxis]\n",
    "#        alpha0 = np.ones(n)[:,np.newaxis]\n",
    "        res = minimize(obj_logistic,alpha0,args=(K,self.y_[:,np.newaxis],self.C),tol=1e-19)\n",
    "        self.alpha = res.x\n",
    "#        print(self.alpha)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        K = self.kernel(self.X_,X)\n",
    "        return np.sign(self.alpha.dot(K))\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return np.mean(self.predict(X) == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "class KernelMultiClassifier():\n",
    "    def __init__(self, baseClassifier=None,C=None, kernel=None, param=None):\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "        self.param = param\n",
    "        self.baseClassifier = baseClassifier\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        datasets_dict = {}\n",
    "        models_dict = {}\n",
    "        l = np.unique(y)\n",
    "        for (class1,class2) in combinations(l, 2):\n",
    "            y1 = y[y==class1]\n",
    "            y1[:] = -1\n",
    "            X1 = X[y==class1]\n",
    "            y2 = y[y==class2]\n",
    "            y2[:] = 1\n",
    "            X2 = X[y==class2]\n",
    "            datasets_dict[(class1,class2)] = (np.concatenate((X1,X2)),np.concatenate((y1,y2)))\n",
    "        for tmp in datasets_dict:\n",
    "            (X_tmp,y_tmp) = datasets_dict[tmp]\n",
    "            model = self.baseClassifier(self.C,self.kernel)\n",
    "            model = model.fit(X_tmp, y_tmp)\n",
    "            models_dict[tmp] = model\n",
    "        self.models_dict = models_dict\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        y = []\n",
    "        for tmp in self.models_dict:\n",
    "            y_pred = self.models_dict[tmp].predict(X)\n",
    "            y_pred[y_pred==-1] = tmp[0]\n",
    "            y_pred[y_pred==1] = tmp[1]\n",
    "            y.append(y_pred)\n",
    "        y = np.array(y)\n",
    "        y_pred_em = stats.mode(y).mode[0]\n",
    "        return y_pred_em\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return np.mean(self.predict(X) == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of algorithms for classification binaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN score: 1.000000\n",
      "LogisticRegression score: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minami_yunji/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/minami_yunji/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/minami_yunji/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:11: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/minami_yunji/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:12: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, neighbors, linear_model\n",
    "\n",
    "digits = datasets.load_digits(n_class=2)\n",
    "X_digits = digits.data\n",
    "y_digits = digits.target\n",
    "\n",
    "n_samples = len(X_digits)\n",
    "\n",
    "X_train = X_digits[:.9 * n_samples]\n",
    "y_train = y_digits[:.9 * n_samples]\n",
    "X_test = X_digits[.9 * n_samples:]\n",
    "y_test = y_digits[.9 * n_samples:]\n",
    "\n",
    "y_train[y_train==0]=-1\n",
    "y_test[y_test==0]=-1\n",
    "\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "logistic = linear_model.LogisticRegression()\n",
    "\n",
    "print('KNN score: %f' % knn.fit(X_train, y_train).score(X_test, y_test))\n",
    "print('LogisticRegression score: %f'\n",
    "      % logistic.fit(X_train, y_train).score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1  1  1  1  1  1 -1  1 -1 -1  1 -1  1 -1  1 -1 -1  1  1 -1 -1 -1  1  1\n",
      " -1 -1 -1  1  1  1  1  1 -1  1 -1]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test for logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import kernel_metrics as km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04294039  0.05082988  0.04146572  0.2454011   0.11934131 -0.04091366\n",
      " -0.05987825 -0.11347775  0.10989935 -0.16090076  0.04300316  0.17633958\n",
      " -0.03096631 -0.00625093 -0.0822451  -0.23505745  0.09379096 -0.04147986\n",
      " -0.00208164 -0.11157896  0.14750004 -0.04448604  0.04731343  0.0970981\n",
      "  0.12498039  0.06199883  0.08155178  0.04442897  0.04457044 -0.132874\n",
      " -0.13191295  0.05222672  0.08458521 -0.24035629 -0.12246602 -0.05008734\n",
      "  0.09358181  0.08910324 -0.06270656  0.15125717  0.10880539  0.07521773\n",
      " -0.05200343 -0.07017554 -0.03489443  0.00942266 -0.07322521  0.13828377\n",
      " -0.14873395  0.06639373  0.01149809 -0.10693744 -0.04626645 -0.03699599\n",
      " -0.03899101  0.15954758 -0.03202556  0.19816371  0.03421334  0.05457759\n",
      "  0.12683134 -0.00990346 -0.09881742  0.18000301  0.05657072 -0.02830526\n",
      "  0.01507126  0.01670076  0.02739768 -0.07871335 -0.01341265  0.09285675\n",
      " -0.0429625  -0.26201316 -0.05777683  0.03216658  0.0225144  -0.0614044\n",
      "  0.00503319 -0.08266114 -0.01469591  0.01565648 -0.25601512 -0.03503236\n",
      " -0.22733756 -0.05483229 -0.17264863 -0.00575432  0.01396876 -0.10758176\n",
      " -0.04723127  0.00773234  0.01110183  0.17610711 -0.01931339  0.02156448\n",
      "  0.21340409  0.12751921  0.0844315   0.04702997  0.03236382 -0.00481066\n",
      " -0.14774381 -0.25225127 -0.10983013 -0.02430517  0.00386115 -0.02144355\n",
      "  0.17760539 -0.03726003 -0.03507685 -0.14955887  0.07782599 -0.15963119\n",
      " -0.15047414 -0.03550342  0.02750931 -0.05601848 -0.22178645  0.03072807\n",
      " -0.08064929  0.01063909  0.08134785 -0.10707034  0.0361857   0.01115677\n",
      " -0.02032776 -0.14322362  0.02231225  0.12171999 -0.02437107  0.18195016\n",
      " -0.00767765  0.03454827 -0.1401278  -0.06105014 -0.0366904  -0.09838843\n",
      " -0.13353469  0.01144722 -0.15896038  0.29897788 -0.01368079  0.04148216\n",
      " -0.21651334  0.05189468  0.07521869  0.05754559  0.04219114  0.08933265\n",
      " -0.04134827  0.08168474 -0.17749244  0.13290696  0.03881709 -0.09529319\n",
      "  0.05900445 -0.15811929  0.0052062   0.07156095 -0.13653519 -0.06603621\n",
      "  0.07080243 -0.09758528  0.04579665 -0.0160611  -0.02373192  0.12880832\n",
      " -0.00042897 -0.14514092 -0.00412868  0.07927509  0.15077757 -0.09648348\n",
      "  0.01826648  0.06996551  0.09541119  0.0152288  -0.04498959 -0.1672976\n",
      " -0.01926136  0.01847288  0.00272553  0.05451687  0.1246738  -0.04281375\n",
      "  0.07003005  0.0186314  -0.05428056  0.10683727  0.0256993  -0.07599528\n",
      "  0.0189636  -0.00889445  0.02020743  0.21222508 -0.00134734 -0.06054221\n",
      " -0.12614103 -0.0105774  -0.14874032  0.04173376  0.18944472  0.07733753\n",
      "  0.15235023 -0.06001777 -0.11822603 -0.19188132 -0.06497401  0.02365237\n",
      " -0.05349142 -0.15868714  0.01249117  0.09795319 -0.10371889 -0.23861515\n",
      "  0.0436577  -0.00524633  0.00544325 -0.12997902 -0.04126559 -0.00476933\n",
      "  0.00719979  0.13448169  0.06195251  0.14745704 -0.09804638  0.07965968\n",
      "  0.06983329 -0.21677337  0.10180516 -0.14488003  0.01608839  0.12055966\n",
      " -0.0997698  -0.07947355 -0.06989538 -0.1641313   0.05335369 -0.09618268\n",
      " -0.01409416  0.03650419  0.04712816 -0.1218449  -0.00654651  0.05368933\n",
      "  0.07276877  0.06977688 -0.04902274 -0.02166734  0.14575675  0.09576552\n",
      " -0.23909488 -0.03942656  0.09694907  0.0237865  -0.03365046 -0.20485901\n",
      " -0.01876607 -0.21652142  0.14644051  0.00511406 -0.14544412  0.0742601\n",
      "  0.0832968   0.14751739 -0.04509918  0.06020369 -0.0637825   0.07038936\n",
      " -0.01343423  0.03113971 -0.00659688  0.06389457 -0.22233757 -0.07432915\n",
      "  0.1307084   0.03113367  0.08651481 -0.13517669  0.17430036 -0.08804119\n",
      " -0.01239471  0.24574364  0.19790426 -0.04346511  0.00353704  0.17347721\n",
      " -0.04335203  0.08158566 -0.04115637 -0.14150683  0.01265174  0.07455125\n",
      " -0.04018244  0.11388283  0.02474005  0.02172276  0.22713497 -0.02925629\n",
      " -0.02787289  0.07203738  0.00075772 -0.14106872 -0.03968353  0.10874543\n",
      "  0.18405238 -0.17399148 -0.02618513 -0.13254254  0.03112229  0.02593988\n",
      " -0.11622595 -0.03819562  0.04985369 -0.09164859 -0.14538306  0.04307465\n",
      "  0.12609706  0.09741281  0.03772279 -0.16376743  0.10633255  0.11969545]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticClassifier(C=1,kernel=km.linear_kernel)\n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47222222222222221"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1., -1., -1.,\n",
       "        1., -1., -1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1., -1.,\n",
       "       -1., -1., -1.,  1.,  1.,  1., -1., -1.,  1., -1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sign(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for multiclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minami_yunji/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/minami_yunji/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/minami_yunji/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:11: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/minami_yunji/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:12: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN score: 0.961111\n",
      "LogisticRegression score: 0.938889\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, neighbors, linear_model\n",
    "\n",
    "digits = datasets.load_digits(n_class=10)\n",
    "X_digits = digits.data\n",
    "y_digits = digits.target\n",
    "\n",
    "n_samples = len(X_digits)\n",
    "\n",
    "X_train = X_digits[:.9 * n_samples]\n",
    "y_train = y_digits[:.9 * n_samples]\n",
    "X_test = X_digits[.9 * n_samples:]\n",
    "y_test = y_digits[.9 * n_samples:]\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "logistic = linear_model.LogisticRegression()\n",
    "\n",
    "print('KNN score: %f' % knn.fit(X_train, y_train).score(X_test, y_test))\n",
    "print('LogisticRegression score: %f'\n",
    "      % logistic.fit(X_train, y_train).score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X_train,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-849ad75fe10d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkernel_metrics\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mkm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKernelMultiClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbaseClassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLogisticClassifier\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_kernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-117-c0ffc614d078>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mX_tmp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_tmp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbaseClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tmp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m             \u001b[0mmodels_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-d072a0632f99>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0malpha0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "import kernel_metrics as km\n",
    "model = KernelMultiClassifier(baseClassifier=LogisticClassifier,C=1,kernel=km.linear_kernel)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18681318681318682"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "1 5\n",
      "2 3\n",
      "2 4\n",
      "2 5\n",
      "3 4\n",
      "3 5\n",
      "4 5\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "for (tmp1,tmp2) in combinations(np.unique([1,2,3,4,5,5]), 2):\n",
    "    print(tmp1,tmp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test by using sklearn's LogisticRegression in multiclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "class KernelMultiClassifier():\n",
    "    def __init__(self, baseClassifier=None,C=None, kernel=None, param=None):\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "        self.param = param\n",
    "        self.baseClassifier = baseClassifier\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        datasets_dict = {}\n",
    "        models_dict = {}\n",
    "        l = np.unique(y)\n",
    "        for (class1,class2) in combinations(l, 2):\n",
    "            y1 = y[y==class1]\n",
    "            y1[:] = -1\n",
    "            X1 = X[y==class1]\n",
    "            y2 = y[y==class2]\n",
    "            y2[:] = 1\n",
    "            X2 = X[y==class2]\n",
    "            datasets_dict[(class1,class2)] = (np.concatenate((X1,X2)),np.concatenate((y1,y2)))\n",
    "        \n",
    "        for tmp in datasets_dict:\n",
    "            (X_tmp,y_tmp) = datasets_dict[tmp]\n",
    "            model = self.baseClassifier()\n",
    "            model = model.fit(X_tmp, y_tmp)\n",
    "            models_dict[tmp] = model\n",
    "        self.models_dict = models_dict\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        y = []\n",
    "        for tmp in self.models_dict:\n",
    "            y_pred = self.models_dict[tmp].predict(X)\n",
    "            y_pred[y_pred==-1] = tmp[0]\n",
    "            y_pred[y_pred==1] = tmp[1]\n",
    "            y.append(y_pred)\n",
    "        y = np.array(y)\n",
    "        y_pred_em = stats.mode(y).mode[0]\n",
    "        return y_pred_em\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return np.mean(self.predict(X) == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.KernelMultiClassifier at 0x7f18fe59a320>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KernelMultiClassifier(baseClassifier=linear_model.LogisticRegression)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 8, 0, 8, 7, 6, 3, 2, 8, 7, 4, 6, 3, 4, 3, 9, 8, 7, 6, 8, 4, 3,\n",
       "       4, 4, 0, 5, 3, 6, 9, 6, 3, 7, 5, 4, 4, 7, 2, 2, 5, 7, 8, 5, 9, 4, 5,\n",
       "       0, 8, 9, 8, 0, 8, 2, 3, 4, 5, 6, 7, 8, 9, 0, 8, 2, 3, 4, 5, 6, 7, 4,\n",
       "       9, 0, 8, 2, 8, 4, 5, 6, 7, 8, 9, 0, 9, 5, 5, 6, 5, 0, 9, 8, 9, 8, 4,\n",
       "       8, 7, 7, 3, 5, 8, 0, 0, 2, 2, 7, 8, 2, 0, 4, 2, 6, 3, 8, 7, 5, 3, 4,\n",
       "       6, 6, 6, 4, 9, 8, 5, 0, 9, 5, 2, 8, 2, 0, 0, 4, 7, 6, 3, 2, 4, 7, 4,\n",
       "       6, 3, 8, 3, 9, 8, 7, 6, 8, 4, 5, 8, 4, 0, 5, 3, 6, 9, 6, 8, 7, 5, 4,\n",
       "       4, 7, 2, 8, 2, 2, 5, 7, 9, 5, 4, 8, 8, 4, 9, 0, 8, 9, 8])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84999999999999998"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
